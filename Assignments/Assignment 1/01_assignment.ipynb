{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# POP77142 Assignment 1: Text Preparation\n",
        "\n",
        "## Before Submission\n",
        "\n",
        "-   Make sure that you can run all cells without errors\n",
        "-   You can do it by clicking `Kernel`, `Restart & Run All` in the menu\n",
        "    above\n",
        "-   Make sure that you save the output by pressing Command+S / CTRL+S\n",
        "-   Rename the file from `01_assignment.ipynb` to\n",
        "    `01_lastname_firstname_studentnumber.ipynb`\n",
        "-   Use Firefox browser for submitting your Jupyter notebook on\n",
        "    Blackboard.\n",
        "\n",
        "## Overview\n",
        "\n",
        "In this assignment you will need to collect and prepare textual data for\n",
        "analysis. As the data source we will debates in the Dáil Éireann (Irish\n",
        "Parliament) for the first 2 months of 2025 (but in practice once you\n",
        "implement a solution for those it should be relatively straightforward\n",
        "to scale up).\n",
        "\n",
        "There are 2 broad strategies that can be used to obtain Dáil debates:\n",
        "\n",
        "1.  Use the [Oireachtas\n",
        "    website](https://www.oireachtas.ie/en/debates/find/) to scrape the\n",
        "    debates using R (e.g. `rvest`) or Python (e.g. `Beautiful Soup`).\n",
        "    There can be different strategies to solve this, but, crucially, the\n",
        "    website is largely static, so dealing with it as a set of HTML files\n",
        "    is quite manageable.\n",
        "2.  Use the [Oireachtas API](https://api.oireachtas.ie/) to scrape the\n",
        "    debates using R (e.g. `httr2`) or Python (e.g. `requests`). This\n",
        "    might be a more advanced option, but it is also a lot more powerful\n",
        "    and flexible. Importantly, this API does not require authentication,\n",
        "    which makes working with it quite a bit simpler than with many other\n",
        "    APIs.\n",
        "\n",
        "## Part 1: Data Acquisition\n",
        "\n",
        "In this part you will need to write a scraper that collects the data\n",
        "either directly from the Oireachtas website or using the Oireachtas API.\n",
        "The data should be collected for the first 2 months of 2025 (January and\n",
        "February, but the bulk of the debates would be in February).\n",
        "\n",
        "Depending on how you choose to organise your code, you may choose to\n",
        "build up a usual tabular dataset straightaway or you might find it\n",
        "easier to store the data in a different container (e.g. a list of\n",
        "vectors, a list of lists, a list of dictionaries, etc.) and then convert\n",
        "it to a tabular format in the next part.\n",
        "\n",
        "You may use generative AI to help you with trialing different\n",
        "approaches. If you do use AI, you need to report the version of the LLM\n",
        "that you are using (e.g. `code-davinci-002`,\n",
        "`meta-llama-3.1-8b-intruct`, etc.). Hardware permitting, I encourage you\n",
        "to use offline models to have better control over the data and the\n",
        "model.\n",
        "\n",
        "While there maybe also some bindings for the API that are readily\n",
        "available, none of them are officially supported, so you shouldn’t be\n",
        "relying on those.\n",
        "\n",
        "## Part 2: Text Preprocessing\n",
        "\n",
        "In this part you will need to clean up the collected data. Depending on\n",
        "how the previous part was implemented it might take more or fewer steps.\n",
        "The ultimate goal is to have a dataset of the following form:\n",
        "\n",
        "| dail | vol | no  | date | speaker | text | ntokens | ntypes |\n",
        "|------|-----|-----|------|---------|------|---------|--------|\n",
        "\n",
        "where:\n",
        "\n",
        "`dail` - is the number of the Dáil (e.g. 34th Dáil)\n",
        "\n",
        "`vol` - is the volume number of the debates (e.g. 1000)\n",
        "\n",
        "`no` - is the number of the debate in the volume (e.g. 1)\n",
        "\n",
        "`date` - is the date of the debate (in YYYY-MM-DD form, e.g. 2025-01-01)\n",
        "\n",
        "`speaker` - is the name of the speaker\n",
        "\n",
        "`text` - is the text of the speech\n",
        "\n",
        "`ntokens` - is the number of tokens in the speech\n",
        "\n",
        "`ntypes` - is the number of types in the speech\n",
        "\n",
        "Note that you **don’t** need to submit the actual dataset. However,\n",
        "after organising the textual data in this way, you will need to perform\n",
        "the following steps:\n",
        "\n",
        "-   Print out the first and last 5 rows of the data\n",
        "-   Print the dimensionality of the data (number of rows and number of\n",
        "    columns)\n",
        "-   Print the total number of unique speakers in the dataset."
      ],
      "id": "81709296-2826-470c-a31d-7fcd6d45a56d"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "ir",
      "display_name": "R",
      "language": "R",
      "path": "/home/tp1587/.local/share/jupyter/kernels/ir"
    },
    "language_info": {
      "name": "R",
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "pygments_lexer": "r",
      "version": "4.4.1"
    }
  }
}